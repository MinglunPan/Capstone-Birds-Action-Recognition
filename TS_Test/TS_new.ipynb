{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9de24a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# import mkl\n",
    "# mkl.set_num_threads(30)\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "import imp\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] =\"2\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#import tensorflow_hub as hub\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils\n",
    "import config\n",
    "import image\n",
    "import dataset\n",
    "import model\n",
    "import IPython\n",
    "#import extract_flow\n",
    "#import extract_RGBframes\n",
    "\n",
    "from utils import getImagePath\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "imp.reload(config)\n",
    "imp.reload(image)\n",
    "imp.reload(utils)\n",
    "imp.reload(dataset)\n",
    "imp.reload(model)\n",
    "#imp.reload(extract_flow)\n",
    "#imp.reload(extract_RGBframes)\n",
    "\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e2343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 02:14:08.372887: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-16 02:14:08.373023: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: midway2-0606.rcc.local\n",
      "2022-10-16 02:14:08.373069: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: midway2-0606.rcc.local\n",
      "2022-10-16 02:14:08.373351: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3\n",
      "2022-10-16 02:14:08.373457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3\n",
      "2022-10-16 02:14:08.373471: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e8806b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_metadata_df = dataset.load_images_metadata()\n",
    "images_metadata_birds_df = images_metadata_df.loc[images_metadata_df['obj_cat_binary']==1].sample(frac = 1, random_state = 42)\n",
    "\n",
    "images_metadata_dict = dataset.load_images_metadata_dict(images_metadata_birds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec3c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "twostream_dict = images_metadata_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02eb283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "isFile = os.path.exists('/project2/msca/xtang36/cap_test_rgb/29285')\n",
    "print(isFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c736adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for obj_id, obj_info in twostream_dict.items():\n",
    "    data_path_v = os.path.join(*[str(x) for x in [config.DATA_DIR, obj_info['day_dir'], obj_info['camera_dir'], \n",
    "                             obj_info['video_dir'], obj_info['track_dir']]])\n",
    "    frame_path_list = [os.path.join(data_path_v, file_path) for file_path in obj_info['image_file']]\n",
    "    #del optical_dict[obj_id]['video_path']\n",
    "    twostream_dict[obj_id]['image_path'] = data_path_v\n",
    "    #optical_dict['frame_']\n",
    "#twostream_dict[29285]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85722943",
   "metadata": {},
   "source": [
    "### Extract New frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d570189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract Optical\n",
    "def compute_TVL1(prev, curr, bound=15):\n",
    "    \"\"\"Compute the TV-L1 optical flow.\"\"\"\n",
    "    TVL1 = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = TVL1.calc(prev, curr, None)\n",
    "    #flow_frame = np.clip(flow_frame, -20, 20)\n",
    "    assert flow.dtype == np.float32\n",
    "\n",
    "    flow = (flow + bound) * (255.0 / (2*bound))\n",
    "    flow = np.round(flow).astype(int)\n",
    "    flow[flow >= 255] = 255\n",
    "    flow[flow <= 0] = 0\n",
    "\n",
    "    return flow\n",
    "\n",
    "def cal_for_frames(video_path):\n",
    "    #print(video_path)\n",
    "    frames = glob(os.path.join(video_path, '*.png'))\n",
    "    frames.sort()\n",
    "    #print(frames)\n",
    "    flow = []\n",
    "    prev = cv2.imread(frames[0])\n",
    "    prev = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "    for i, frame_curr in enumerate(frames):\n",
    "        curr = cv2.imread(frame_curr)\n",
    "        curr = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "        tmp_flow = compute_TVL1(prev, curr)\n",
    "        flow.append(tmp_flow)\n",
    "        prev = curr\n",
    "\n",
    "    return flow\n",
    "\n",
    "def save_flow(video_flows, flow_path):\n",
    "    for i, flow in enumerate(video_flows):\n",
    "        cv2.imwrite(os.path.join(flow_path.format('u'), \"{}_{:06d}.jpg\".format(obj_id, i)), flow[:, :, 0])\n",
    "        cv2.imwrite(os.path.join(flow_path.format('v'), \"{}_{:06d}.jpg\".format(obj_id, i)), flow[:, :, 1])\n",
    "        \n",
    "def extract_flow(args):\n",
    "    video_path, flow_path = args\n",
    "    flow = cal_for_frames(video_path)\n",
    "    save_flow(flow, flow_path)\n",
    "    #print('complete:' + flow_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddd5b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract RGB\n",
    "def cal_for_RGB_frames(video_path):\n",
    "    #print(video_path)\n",
    "    frames = glob(os.path.join(video_path, '*.png'))\n",
    "    frames.sort()\n",
    "    #print(frames)\n",
    "    flow = []\n",
    "    for f in frames:\n",
    "        rgb_frame = cv2.imread(f)\n",
    "        rgb_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2HSV)\n",
    "        flow.append(rgb_frame)\n",
    "\n",
    "    return flow\n",
    "\n",
    "def save_flow(video_flows, flow_path):\n",
    "    for i, flow in enumerate(video_flows):\n",
    "        cv2.imwrite(os.path.join(flow_path.format('u'), \"{}_{:06d}.jpg\".format(obj_id, i)), flow[:, :, 0])\n",
    "        cv2.imwrite(os.path.join(flow_path.format('v'), \"{}_{:06d}.jpg\".format(obj_id, i)), flow[:, :, 1])\n",
    "        \n",
    "def extract_RGBframes(args):\n",
    "    video_path, flow_path = args\n",
    "    flow = cal_for_RGB_frames(video_path)\n",
    "    save_flow(flow, flow_path)\n",
    "    #print('complete:' + flow_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7690fc4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day_dir': '2020-09-02-mw2',\n",
       " 'camera_dir': 'dnncame',\n",
       " 'video_dir': 'video-00112-2020_08_31_21_58_14',\n",
       " 'track_dir': 321,\n",
       " 'directory_x': '/video-00112-2020_08_31_21_58_14/321',\n",
       " 'count': 1,\n",
       " 'id': 321,\n",
       " 'directory_y': '/video-00112-2020_08_31_21_58_14/321',\n",
       " 'bird': 1,\n",
       " 'cable': 0,\n",
       " 'panel': 0,\n",
       " 'plant': 0,\n",
       " 'car': 0,\n",
       " 'human': 0,\n",
       " 'other_animal': 0,\n",
       " 'insect': 0,\n",
       " 'aircraft': 0,\n",
       " 'other': 0,\n",
       " 'unknown': 0,\n",
       " 'fly_over_above': 1,\n",
       " 'fly_over_reflection': 0,\n",
       " 'fly_through': 0,\n",
       " 'perch_on_panel': 0,\n",
       " 'land_on_ground': 0,\n",
       " 'perch_in_background': 0,\n",
       " 'collision': 0,\n",
       " 'uncertain': 0,\n",
       " 'image_count': 50,\n",
       " 'obj_cat': 1,\n",
       " 'obj_cat_binary': 1,\n",
       " 'activity_cat': 1,\n",
       " 'ttv_split': 1.0,\n",
       " 'image_file': ['video-00112-2020_08_31_21_58_14_8771_916_632_42.32322_13456_321_275.1944289077348_272.116035335796_[44.18144407].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8751_1572_644_22.54145_12769_321_272.3859440303888_250.642313350809_[24.0208243].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8766_1124_624_36.82334_13338_321_274.5139884580013_270.6368826984295_[38.11823711].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8777_648_649_45.16409_13688_321_273.81407483429035_273.669764567054_[45.09988914].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8753_1528_634_22.53746_12317_321_254.74488129694225_251.72283203860889_[22.8035085].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8785_296_698_44.03708_13225_321_285.9453959009229_277.87535709974_[43.68065934].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8736_1907_637_24.36159_12544_321_280.0079798014413_90.0_[17.2626765].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8738_1870_642_24.36159_12543_321_278.9726266148964_269.97801782331794_[19.23538406].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8787_212_713_43.13190_13570_321_284.67639313744996_279.86813906416006_[43.41658669].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8739_1849_644_24.36159_12880_321_275.4403320310055_273.90678849527626_[21.09502311].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8743_1754_656_24.36159_12656_321_274.5739212599009_278.0875198778617_[25.07987241].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8768_1044_627_39.09086_13920_321_279.9262455066517_270.18581495861963_[40.60788101].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8756_1452_627_24.88482_12432_321_259.1144729453413_262.9288724520276_[26.47640459].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8737_1889_639_24.36159_12544_321_276.3401917459099_265.9910821166177_[18.11077028].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8770_960_628_41.15599_13455_321_271.36392753160294_272.5160004218677_[42.01190308].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8775_738_643_44.71814_13688_321_273.73139699916044_273.6277239870924_[46.09772229].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8734_1924_634_24.36159_12321_321_0_0_0.png',\n",
       "  'video-00112-2020_08_31_21_58_14_8750_1596_643_22.37017_12882_321_203.86252411193664_277.4181479657993_[34.66725783].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8779_558_658_45.22963_13570_321_276.3401917459099_274.1508372144028_[45.27692569].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8772_872_634_43.19894_13455_321_272.6025622024998_272.97531731247284_[44.04543109].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8780_514_662_44.92383_13804_321_275.1944289077348_274.94281919192355_[44.18144407].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8742_1779_654_24.36159_12656_321_279.09027692082236_277.05505056628886_[25.3179778].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8781_470_664_44.55496_13456_321_272.6025622024998_275.2644086704571_[44.04543109].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8782_425_676_44.88577_13804_321_284.9314171781375_274.5454256666645_[46.57252409].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8752_1550_640_22.44998_12543_321_259.6951535312339_249.01232034748818_[22.36067977].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8774_784_640_44.01064_13340_321_272.6025622024998_273.7840842588257_[44.04543109].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8776_693_646_45.04824_13572_321_273.81407483429035_273.6133122173751_[45.09988914].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8788_172_726_42.69028_12882_321_288.0041616059134_281.10904018985605_[42.05948169].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8765_1162_621_35.75314_13452_321_274.6354634269027_269.16597182679743_[37.12142239].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8759_1368_619_27.78498_13216_321_260.2175929681928_264.83960174628044_[29.42787794].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8758_1397_624_26.75433_13110_321_257.4711922908484_266.38782890358016_[27.65863337].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8784_338_686_44.33677_13572_321_280.304846468766_277.06029598452517_[44.72135955].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8773_828_638_43.75579_13455_321_275.1944289077348_273.1041872030204_[44.18144407].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8757_1424_630_25.98436_12995_321_276.1155035662854_262.03465494083434_[28.16025568].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8762_1270_616_32.06750_13221_321_264.95754893082903_266.89113371408484_[34.13209633].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8764_1199_618_34.55460_13224_321_263.82982490497034_270.02562527069_[37.21558813].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8783_382_678_44.40372_13455_321_272.66300076606717_277.5871065518538_[43.0464865].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8735_1924_634_24.36159_12321_321_90.0_90.0_[0.].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8740_1828_646_24.36159_12543_321_275.4403320310055_275.298161916892_[21.09502311].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8761_1304_619_30.57576_13108_321_259.3803447238449_268.26281881474563_[32.55764119].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8786_254_702_43.35534_13340_321_275.4403320310055_280.5538325903112_[42.19004622].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8763_1236_622_33.03505_13108_321_280.0079798014413_265.8600635463406_[34.525353].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8755_1478_632_23.92781_12769_321_258.2317110679794_261.64027296035874_[24.51530134].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8767_1084_620_38.07930_13225_321_264.2894068625003_272.2880246251127_[40.19950248].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8778_603_653_45.20076_13920_321_275.07960786001456_273.72780747628076_[45.17742799].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8789_132_731_41.78104_12882_321_277.1250163489018_283.5580899668231_[40.31128874].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8769_1002_627_40.27350_13688_321_270.0_272.64515385917156_[42.].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8741_1804_650_24.36159_12768_321_279.4623222080256_275.68376777563753_[24.33105012].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8754_1502_637_23.26703_13110_321_276.581944655178_253.42187002214996_[26.17250466].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8760_1336_625_29.20457_13224_321_280.61965527615513_262.87888758539725_[32.55764119].png'],\n",
       " 'x': [916,\n",
       "  1572,\n",
       "  1124,\n",
       "  648,\n",
       "  1528,\n",
       "  296,\n",
       "  1907,\n",
       "  1870,\n",
       "  212,\n",
       "  1849,\n",
       "  1754,\n",
       "  1044,\n",
       "  1452,\n",
       "  1889,\n",
       "  960,\n",
       "  738,\n",
       "  1924,\n",
       "  1596,\n",
       "  558,\n",
       "  872,\n",
       "  514,\n",
       "  1779,\n",
       "  470,\n",
       "  425,\n",
       "  1550,\n",
       "  784,\n",
       "  693,\n",
       "  172,\n",
       "  1162,\n",
       "  1368,\n",
       "  1397,\n",
       "  338,\n",
       "  828,\n",
       "  1424,\n",
       "  1270,\n",
       "  1199,\n",
       "  382,\n",
       "  1924,\n",
       "  1828,\n",
       "  1304,\n",
       "  254,\n",
       "  1236,\n",
       "  1478,\n",
       "  1084,\n",
       "  603,\n",
       "  132,\n",
       "  1002,\n",
       "  1804,\n",
       "  1502,\n",
       "  1336],\n",
       " 'y': [632,\n",
       "  644,\n",
       "  624,\n",
       "  649,\n",
       "  634,\n",
       "  698,\n",
       "  637,\n",
       "  642,\n",
       "  713,\n",
       "  644,\n",
       "  656,\n",
       "  627,\n",
       "  627,\n",
       "  639,\n",
       "  628,\n",
       "  643,\n",
       "  634,\n",
       "  643,\n",
       "  658,\n",
       "  634,\n",
       "  662,\n",
       "  654,\n",
       "  664,\n",
       "  676,\n",
       "  640,\n",
       "  640,\n",
       "  646,\n",
       "  726,\n",
       "  621,\n",
       "  619,\n",
       "  624,\n",
       "  686,\n",
       "  638,\n",
       "  630,\n",
       "  616,\n",
       "  618,\n",
       "  678,\n",
       "  634,\n",
       "  646,\n",
       "  619,\n",
       "  702,\n",
       "  622,\n",
       "  632,\n",
       "  620,\n",
       "  653,\n",
       "  731,\n",
       "  627,\n",
       "  650,\n",
       "  637,\n",
       "  625],\n",
       " 'speed': [42.32322,\n",
       "  22.54145,\n",
       "  36.82334,\n",
       "  45.16409,\n",
       "  22.53746,\n",
       "  44.03708,\n",
       "  24.36159,\n",
       "  24.36159,\n",
       "  43.1319,\n",
       "  24.36159,\n",
       "  24.36159,\n",
       "  39.09086,\n",
       "  24.88482,\n",
       "  24.36159,\n",
       "  41.15599,\n",
       "  44.718140000000005,\n",
       "  24.36159,\n",
       "  22.37017,\n",
       "  45.22963,\n",
       "  43.19894,\n",
       "  44.92383,\n",
       "  24.36159,\n",
       "  44.55496,\n",
       "  44.88577,\n",
       "  22.44998,\n",
       "  44.01064,\n",
       "  45.04824,\n",
       "  42.69028,\n",
       "  35.75314,\n",
       "  27.78498,\n",
       "  26.75433,\n",
       "  44.33677,\n",
       "  43.755790000000005,\n",
       "  25.98436,\n",
       "  32.0675,\n",
       "  34.5546,\n",
       "  44.40372,\n",
       "  24.36159,\n",
       "  24.36159,\n",
       "  30.57576,\n",
       "  43.355340000000005,\n",
       "  33.03505,\n",
       "  23.92781,\n",
       "  38.0793,\n",
       "  45.20076,\n",
       "  41.78104,\n",
       "  40.2735,\n",
       "  24.36159,\n",
       "  23.26703,\n",
       "  29.20457],\n",
       " 'area': [13456,\n",
       "  12769,\n",
       "  13338,\n",
       "  13688,\n",
       "  12317,\n",
       "  13225,\n",
       "  12544,\n",
       "  12543,\n",
       "  13570,\n",
       "  12880,\n",
       "  12656,\n",
       "  13920,\n",
       "  12432,\n",
       "  12544,\n",
       "  13455,\n",
       "  13688,\n",
       "  12321,\n",
       "  12882,\n",
       "  13570,\n",
       "  13455,\n",
       "  13804,\n",
       "  12656,\n",
       "  13456,\n",
       "  13804,\n",
       "  12543,\n",
       "  13340,\n",
       "  13572,\n",
       "  12882,\n",
       "  13452,\n",
       "  13216,\n",
       "  13110,\n",
       "  13572,\n",
       "  13455,\n",
       "  12995,\n",
       "  13221,\n",
       "  13224,\n",
       "  13455,\n",
       "  12321,\n",
       "  12543,\n",
       "  13108,\n",
       "  13340,\n",
       "  13108,\n",
       "  12769,\n",
       "  13225,\n",
       "  13920,\n",
       "  12882,\n",
       "  13688,\n",
       "  12768,\n",
       "  13110,\n",
       "  13224],\n",
       " 'image_path': '/project2/msca/projects/AvianSolar/ImageDataset/raw_dataset/2020-09-02-mw2/dnncame/video-00112-2020_08_31_21_58_14/321'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twostream_dict[29285]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8065965",
   "metadata": {},
   "source": [
    "### New Frame Generation -- SKIP FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7bfa7ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m opt_input_path \u001b[38;5;241m=\u001b[39m obj_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     41\u001b[0m args \u001b[38;5;241m=\u001b[39m opt_input_path, new_path\n\u001b[0;32m---> 42\u001b[0m \u001b[43mextract_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m opt_output_frames \u001b[38;5;241m=\u001b[39m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(new_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     44\u001b[0m opt_output_frames\u001b[38;5;241m.\u001b[39msort()\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mextract_flow\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_flow\u001b[39m(args):\n\u001b[1;32m     40\u001b[0m     video_path, flow_path \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m---> 41\u001b[0m     flow \u001b[38;5;241m=\u001b[39m \u001b[43mcal_for_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     save_flow(flow, flow_path)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#print('complete:' + flow_path)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mcal_for_frames\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m curr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(frame_curr)\n\u001b[1;32m     26\u001b[0m curr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(curr, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m---> 27\u001b[0m tmp_flow \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_TVL1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m flow\u001b[38;5;241m.\u001b[39mappend(tmp_flow)\n\u001b[1;32m     29\u001b[0m prev \u001b[38;5;241m=\u001b[39m curr\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mcompute_TVL1\u001b[0;34m(prev, curr, bound)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the TV-L1 optical flow.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m TVL1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39moptflow\u001b[38;5;241m.\u001b[39mDualTVL1OpticalFlow_create()\n\u001b[0;32m----> 5\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43mTVL1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#flow_frame = np.clip(flow_frame, -20, 20)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m flow\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rgb_flow_path='/project2/msca/xtang36/cap_test_rgb/'\n",
    "optical_flow_path='/project2/msca/xtang36/cap_test_optical/'\n",
    "n_rgb = 0\n",
    "n_opt = 0\n",
    "#add rgb image path to the data_dictionary\n",
    "for obj_id, obj_info in twostream_dict.items():\n",
    "    if n_rgb <=8000:\n",
    "\n",
    "        directory = str(obj_id)\n",
    "        new_path = os.path.join(rgb_flow_path, directory)\n",
    "        isFile = os.path.exists(new_path)\n",
    "        if isFile == True:\n",
    "            #print(\"path\", new_path, \"is already exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(new_path)\n",
    "            os.mkdir(new_path)\n",
    "        opt_input_path = obj_info['image_path']\n",
    "        args = opt_input_path, new_path\n",
    "        extract_RGBframes(args)\n",
    "        opt_output_frames = glob(os.path.join(new_path, '*.jpg'))\n",
    "        opt_output_frames.sort()\n",
    "        twostream_dict[obj_id]['rgb_files'] = opt_output_frames\n",
    "        n_rgb+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print('RBG done')\n",
    "#add optical flow image path to the data_dictionary\n",
    "for obj_id, obj_info in twostream_dict.items():\n",
    "    if n_opt <=8000:\n",
    "        directory = str(obj_id)\n",
    "        new_path = os.path.join(optical_flow_path, directory)\n",
    "        isFile = os.path.exists(new_path)\n",
    "        if isFile == True:\n",
    "            #print(\"path\", new_path, \"is already exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(new_path)\n",
    "            os.mkdir(new_path)\n",
    "        opt_input_path = obj_info['image_path']\n",
    "        args = opt_input_path, new_path\n",
    "        extract_flow(args)\n",
    "        opt_output_frames = glob(os.path.join(new_path, '*.jpg'))\n",
    "        opt_output_frames.sort()\n",
    "        twostream_dict[obj_id]['optical_files'] = opt_output_frames\n",
    "        n_opt +=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4268d01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get rgb and optical flow images from file path into the data dict\n",
    "for obj_id, obj_info in twostream_dict.items():\n",
    "    data_path_opt = os.path.join(\"/project2/msca/xtang36/cap_test_optical\", str(obj_id))\n",
    "    data_path_rgb = os.path.join(\"/project2/msca/xtang36/cap_test_rgb\", str(obj_id))\n",
    "    isFile_opt = os.path.exists(data_path_opt)\n",
    "    isFile_rgb = os.path.exists(data_path_rgb)\n",
    "    if isFile_opt == True:\n",
    "        opt_output_frames = glob(os.path.join(data_path_opt, '*.jpg'))\n",
    "        opt_output_frames.sort()\n",
    "        twostream_dict[obj_id]['optical_files'] = opt_output_frames\n",
    "        #print('optical flow frames are added to the dict')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if isFile_rgb == True:\n",
    "        rgb_output_frames = glob(os.path.join(data_path_rgb, '*.jpg'))\n",
    "        rgb_output_frames.sort()\n",
    "        twostream_dict[obj_id]['rgb_files'] = rgb_output_frames\n",
    "        #print('rgb frames are added to the dict')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18d352ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17155"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twostream_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9d00c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day_dir': '2020-09-02-mw2',\n",
       " 'camera_dir': 'dnncame',\n",
       " 'video_dir': 'video-00112-2020_08_31_21_58_14',\n",
       " 'track_dir': 321,\n",
       " 'directory_x': '/video-00112-2020_08_31_21_58_14/321',\n",
       " 'count': 1,\n",
       " 'id': 321,\n",
       " 'directory_y': '/video-00112-2020_08_31_21_58_14/321',\n",
       " 'bird': 1,\n",
       " 'cable': 0,\n",
       " 'panel': 0,\n",
       " 'plant': 0,\n",
       " 'car': 0,\n",
       " 'human': 0,\n",
       " 'other_animal': 0,\n",
       " 'insect': 0,\n",
       " 'aircraft': 0,\n",
       " 'other': 0,\n",
       " 'unknown': 0,\n",
       " 'fly_over_above': 1,\n",
       " 'fly_over_reflection': 0,\n",
       " 'fly_through': 0,\n",
       " 'perch_on_panel': 0,\n",
       " 'land_on_ground': 0,\n",
       " 'perch_in_background': 0,\n",
       " 'collision': 0,\n",
       " 'uncertain': 0,\n",
       " 'image_count': 50,\n",
       " 'obj_cat': 1,\n",
       " 'obj_cat_binary': 1,\n",
       " 'activity_cat': 1,\n",
       " 'ttv_split': 1.0,\n",
       " 'image_file': ['video-00112-2020_08_31_21_58_14_8771_916_632_42.32322_13456_321_275.1944289077348_272.116035335796_[44.18144407].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8751_1572_644_22.54145_12769_321_272.3859440303888_250.642313350809_[24.0208243].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8766_1124_624_36.82334_13338_321_274.5139884580013_270.6368826984295_[38.11823711].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8777_648_649_45.16409_13688_321_273.81407483429035_273.669764567054_[45.09988914].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8753_1528_634_22.53746_12317_321_254.74488129694225_251.72283203860889_[22.8035085].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8785_296_698_44.03708_13225_321_285.9453959009229_277.87535709974_[43.68065934].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8736_1907_637_24.36159_12544_321_280.0079798014413_90.0_[17.2626765].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8738_1870_642_24.36159_12543_321_278.9726266148964_269.97801782331794_[19.23538406].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8787_212_713_43.13190_13570_321_284.67639313744996_279.86813906416006_[43.41658669].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8739_1849_644_24.36159_12880_321_275.4403320310055_273.90678849527626_[21.09502311].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8743_1754_656_24.36159_12656_321_274.5739212599009_278.0875198778617_[25.07987241].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8768_1044_627_39.09086_13920_321_279.9262455066517_270.18581495861963_[40.60788101].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8756_1452_627_24.88482_12432_321_259.1144729453413_262.9288724520276_[26.47640459].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8737_1889_639_24.36159_12544_321_276.3401917459099_265.9910821166177_[18.11077028].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8770_960_628_41.15599_13455_321_271.36392753160294_272.5160004218677_[42.01190308].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8775_738_643_44.71814_13688_321_273.73139699916044_273.6277239870924_[46.09772229].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8734_1924_634_24.36159_12321_321_0_0_0.png',\n",
       "  'video-00112-2020_08_31_21_58_14_8750_1596_643_22.37017_12882_321_203.86252411193664_277.4181479657993_[34.66725783].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8779_558_658_45.22963_13570_321_276.3401917459099_274.1508372144028_[45.27692569].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8772_872_634_43.19894_13455_321_272.6025622024998_272.97531731247284_[44.04543109].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8780_514_662_44.92383_13804_321_275.1944289077348_274.94281919192355_[44.18144407].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8742_1779_654_24.36159_12656_321_279.09027692082236_277.05505056628886_[25.3179778].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8781_470_664_44.55496_13456_321_272.6025622024998_275.2644086704571_[44.04543109].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8782_425_676_44.88577_13804_321_284.9314171781375_274.5454256666645_[46.57252409].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8752_1550_640_22.44998_12543_321_259.6951535312339_249.01232034748818_[22.36067977].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8774_784_640_44.01064_13340_321_272.6025622024998_273.7840842588257_[44.04543109].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8776_693_646_45.04824_13572_321_273.81407483429035_273.6133122173751_[45.09988914].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8788_172_726_42.69028_12882_321_288.0041616059134_281.10904018985605_[42.05948169].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8765_1162_621_35.75314_13452_321_274.6354634269027_269.16597182679743_[37.12142239].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8759_1368_619_27.78498_13216_321_260.2175929681928_264.83960174628044_[29.42787794].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8758_1397_624_26.75433_13110_321_257.4711922908484_266.38782890358016_[27.65863337].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8784_338_686_44.33677_13572_321_280.304846468766_277.06029598452517_[44.72135955].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8773_828_638_43.75579_13455_321_275.1944289077348_273.1041872030204_[44.18144407].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8757_1424_630_25.98436_12995_321_276.1155035662854_262.03465494083434_[28.16025568].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8762_1270_616_32.06750_13221_321_264.95754893082903_266.89113371408484_[34.13209633].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8764_1199_618_34.55460_13224_321_263.82982490497034_270.02562527069_[37.21558813].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8783_382_678_44.40372_13455_321_272.66300076606717_277.5871065518538_[43.0464865].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8735_1924_634_24.36159_12321_321_90.0_90.0_[0.].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8740_1828_646_24.36159_12543_321_275.4403320310055_275.298161916892_[21.09502311].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8761_1304_619_30.57576_13108_321_259.3803447238449_268.26281881474563_[32.55764119].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8786_254_702_43.35534_13340_321_275.4403320310055_280.5538325903112_[42.19004622].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8763_1236_622_33.03505_13108_321_280.0079798014413_265.8600635463406_[34.525353].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8755_1478_632_23.92781_12769_321_258.2317110679794_261.64027296035874_[24.51530134].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8767_1084_620_38.07930_13225_321_264.2894068625003_272.2880246251127_[40.19950248].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8778_603_653_45.20076_13920_321_275.07960786001456_273.72780747628076_[45.17742799].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8789_132_731_41.78104_12882_321_277.1250163489018_283.5580899668231_[40.31128874].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8769_1002_627_40.27350_13688_321_270.0_272.64515385917156_[42.].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8741_1804_650_24.36159_12768_321_279.4623222080256_275.68376777563753_[24.33105012].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8754_1502_637_23.26703_13110_321_276.581944655178_253.42187002214996_[26.17250466].png',\n",
       "  'video-00112-2020_08_31_21_58_14_8760_1336_625_29.20457_13224_321_280.61965527615513_262.87888758539725_[32.55764119].png'],\n",
       " 'x': [916,\n",
       "  1572,\n",
       "  1124,\n",
       "  648,\n",
       "  1528,\n",
       "  296,\n",
       "  1907,\n",
       "  1870,\n",
       "  212,\n",
       "  1849,\n",
       "  1754,\n",
       "  1044,\n",
       "  1452,\n",
       "  1889,\n",
       "  960,\n",
       "  738,\n",
       "  1924,\n",
       "  1596,\n",
       "  558,\n",
       "  872,\n",
       "  514,\n",
       "  1779,\n",
       "  470,\n",
       "  425,\n",
       "  1550,\n",
       "  784,\n",
       "  693,\n",
       "  172,\n",
       "  1162,\n",
       "  1368,\n",
       "  1397,\n",
       "  338,\n",
       "  828,\n",
       "  1424,\n",
       "  1270,\n",
       "  1199,\n",
       "  382,\n",
       "  1924,\n",
       "  1828,\n",
       "  1304,\n",
       "  254,\n",
       "  1236,\n",
       "  1478,\n",
       "  1084,\n",
       "  603,\n",
       "  132,\n",
       "  1002,\n",
       "  1804,\n",
       "  1502,\n",
       "  1336],\n",
       " 'y': [632,\n",
       "  644,\n",
       "  624,\n",
       "  649,\n",
       "  634,\n",
       "  698,\n",
       "  637,\n",
       "  642,\n",
       "  713,\n",
       "  644,\n",
       "  656,\n",
       "  627,\n",
       "  627,\n",
       "  639,\n",
       "  628,\n",
       "  643,\n",
       "  634,\n",
       "  643,\n",
       "  658,\n",
       "  634,\n",
       "  662,\n",
       "  654,\n",
       "  664,\n",
       "  676,\n",
       "  640,\n",
       "  640,\n",
       "  646,\n",
       "  726,\n",
       "  621,\n",
       "  619,\n",
       "  624,\n",
       "  686,\n",
       "  638,\n",
       "  630,\n",
       "  616,\n",
       "  618,\n",
       "  678,\n",
       "  634,\n",
       "  646,\n",
       "  619,\n",
       "  702,\n",
       "  622,\n",
       "  632,\n",
       "  620,\n",
       "  653,\n",
       "  731,\n",
       "  627,\n",
       "  650,\n",
       "  637,\n",
       "  625],\n",
       " 'speed': [42.32322,\n",
       "  22.54145,\n",
       "  36.82334,\n",
       "  45.16409,\n",
       "  22.53746,\n",
       "  44.03708,\n",
       "  24.36159,\n",
       "  24.36159,\n",
       "  43.1319,\n",
       "  24.36159,\n",
       "  24.36159,\n",
       "  39.09086,\n",
       "  24.88482,\n",
       "  24.36159,\n",
       "  41.15599,\n",
       "  44.718140000000005,\n",
       "  24.36159,\n",
       "  22.37017,\n",
       "  45.22963,\n",
       "  43.19894,\n",
       "  44.92383,\n",
       "  24.36159,\n",
       "  44.55496,\n",
       "  44.88577,\n",
       "  22.44998,\n",
       "  44.01064,\n",
       "  45.04824,\n",
       "  42.69028,\n",
       "  35.75314,\n",
       "  27.78498,\n",
       "  26.75433,\n",
       "  44.33677,\n",
       "  43.755790000000005,\n",
       "  25.98436,\n",
       "  32.0675,\n",
       "  34.5546,\n",
       "  44.40372,\n",
       "  24.36159,\n",
       "  24.36159,\n",
       "  30.57576,\n",
       "  43.355340000000005,\n",
       "  33.03505,\n",
       "  23.92781,\n",
       "  38.0793,\n",
       "  45.20076,\n",
       "  41.78104,\n",
       "  40.2735,\n",
       "  24.36159,\n",
       "  23.26703,\n",
       "  29.20457],\n",
       " 'area': [13456,\n",
       "  12769,\n",
       "  13338,\n",
       "  13688,\n",
       "  12317,\n",
       "  13225,\n",
       "  12544,\n",
       "  12543,\n",
       "  13570,\n",
       "  12880,\n",
       "  12656,\n",
       "  13920,\n",
       "  12432,\n",
       "  12544,\n",
       "  13455,\n",
       "  13688,\n",
       "  12321,\n",
       "  12882,\n",
       "  13570,\n",
       "  13455,\n",
       "  13804,\n",
       "  12656,\n",
       "  13456,\n",
       "  13804,\n",
       "  12543,\n",
       "  13340,\n",
       "  13572,\n",
       "  12882,\n",
       "  13452,\n",
       "  13216,\n",
       "  13110,\n",
       "  13572,\n",
       "  13455,\n",
       "  12995,\n",
       "  13221,\n",
       "  13224,\n",
       "  13455,\n",
       "  12321,\n",
       "  12543,\n",
       "  13108,\n",
       "  13340,\n",
       "  13108,\n",
       "  12769,\n",
       "  13225,\n",
       "  13920,\n",
       "  12882,\n",
       "  13688,\n",
       "  12768,\n",
       "  13110,\n",
       "  13224],\n",
       " 'image_path': '/project2/msca/projects/AvianSolar/ImageDataset/raw_dataset/2020-09-02-mw2/dnncame/video-00112-2020_08_31_21_58_14/321',\n",
       " 'rgb_files': ['/project2/msca/xtang36/cap_test_rgb/29285/29285_000000.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000001.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000002.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000003.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000004.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000005.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000006.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000007.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000008.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000009.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000010.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000011.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000012.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000013.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000014.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000015.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000016.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000017.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000018.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000019.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000020.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000021.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000022.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000023.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000024.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000025.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000026.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000027.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000028.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000029.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000030.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000031.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000032.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000033.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000034.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000035.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000036.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000037.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000038.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000039.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000040.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000041.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000042.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000043.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000044.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000045.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000046.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000047.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000048.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/29285_000049.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000000.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000001.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000002.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000003.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000004.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000005.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000006.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000007.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000008.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000009.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000010.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000011.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000012.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000013.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000014.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000015.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000016.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000017.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000018.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000019.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000020.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000021.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000022.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000023.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000024.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000025.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000026.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000027.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000028.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000029.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000030.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000031.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000032.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000033.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000034.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000035.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000036.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000037.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000038.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000039.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000040.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000041.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000042.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000043.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000044.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000045.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000046.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000047.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000048.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_rgb/29285/8629_000049.jpg'],\n",
       " 'optical_files': ['/project2/msca/xtang36/cap_test_optical/29285/29285_000000.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000001.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000002.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000003.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000004.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000005.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000006.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000007.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000008.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000009.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000010.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000011.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000012.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000013.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000014.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000015.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000016.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000017.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000018.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000019.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000020.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000021.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000022.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000023.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000024.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000025.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000026.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000027.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000028.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000029.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000030.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000031.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000032.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000033.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000034.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000035.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000036.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000037.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000038.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000039.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000040.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000041.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000042.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000043.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000044.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000045.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000046.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000047.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000048.jpg',\n",
       "  '/project2/msca/xtang36/cap_test_optical/29285/29285_000049.jpg']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twostream_dict[29285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8153987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/project2/msca/xtang36/cap_test_rgb\"\n",
    "obj_id_ = 29285\n",
    "\n",
    "frame_path_list = [os.path.join(*[data_dir, str(obj_id) ,file_path]) for file_path in twostream_dict[obj_id_]['rgb_files']]\n",
    "print(len(frame_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d36d3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_dataset_activity_ts_rgb(obj_metadata_dict):\n",
    "    data_dir = \"/project2/msca/xtang36/cap_test_rgb\"\n",
    "    for obj_id, obj_info in obj_metadata_dict.items():\n",
    "        \n",
    "        data_path_rgb = os.path.join(data_dir, str(obj_id))\n",
    "        isFile_rgb = os.path.exists(data_path_rgb)\n",
    "        if isFile_opt == True:\n",
    "            frame_path_list = [os.path.join(*[data_dir, str(obj_id) ,file_path]) for file_path in obj_info['rgb_files']]\n",
    "            # Counter\n",
    "            num_total_frames = len(frame_path_list) # the number of imgs in this track\n",
    "            num_used_frames = min(config.NUM_INPUT_FRAME, num_total_frames)\n",
    "            num_blank_frames = config.NUM_INPUT_FRAME - num_used_frames\n",
    "            num_skip_at_begining = max(0, (num_total_frames-config.NUM_INPUT_FRAME) >> 1)\n",
    "\n",
    "            # Frames\n",
    "            frames = np.zeros([config.NUM_INPUT_FRAME, config.IMG_HEIGHT,  config.IMG_WIDTH,  config.NUM_CHANNEL])\n",
    "            frames[:num_used_frames] = tf.image.resize(\n",
    "                np.stack([\n",
    "                    image.load(frame_path_list[num_skip_at_begining+frame_idx]) \n",
    "                    for frame_idx in range(num_used_frames)]\n",
    "                ), [config.IMG_HEIGHT, config.IMG_WIDTH])\n",
    "\n",
    "            frames = tf.convert_to_tensor(frames, tf.float32)\n",
    "            # Labels\n",
    "            label = obj_info['activity_cat']\n",
    "            yield frames, label\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8caabeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_dataset_activity_ts_opt(obj_metadata_dict):\n",
    "    data_dir = \"/project2/msca/xtang36/cap_test_optical\"\n",
    "    for obj_id, obj_info in obj_metadata_dict.items():\n",
    "        \n",
    "        data_path_opt = os.path.join(data_dir, str(obj_id))\n",
    "        isFile_opt = os.path.exists(data_path_opt)\n",
    "        if isFile_opt == True:\n",
    "            frame_path_list = [os.path.join(*[data_dir, str(obj_id) ,file_path]) for file_path in obj_info['optical_files']]\n",
    "            # Counter\n",
    "            num_total_frames = len(frame_path_list) # the number of imgs in this track\n",
    "            num_used_frames = min(config.NUM_INPUT_FRAME, num_total_frames)\n",
    "            num_blank_frames = config.NUM_INPUT_FRAME - num_used_frames\n",
    "            num_skip_at_begining = max(0, (num_total_frames-config.NUM_INPUT_FRAME) >> 1)\n",
    "\n",
    "            # Frames\n",
    "            frames = np.zeros([config.NUM_INPUT_FRAME, config.IMG_HEIGHT,  config.IMG_WIDTH,  config.NUM_CHANNEL])\n",
    "            frames[:num_used_frames] = tf.image.resize(\n",
    "                np.stack([\n",
    "                    image.load(frame_path_list[num_skip_at_begining+frame_idx]) \n",
    "                    for frame_idx in range(num_used_frames)]\n",
    "                ), [config.IMG_HEIGHT, config.IMG_WIDTH])\n",
    "\n",
    "            frames = tf.convert_to_tensor(frames, tf.float32)\n",
    "            # Labels\n",
    "            label = obj_info['activity_cat']\n",
    "            yield frames, label\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85c49f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dataset_rgb = {'train':dict(), 'valid':dict(), 'test':dict()}\n",
    "for obj_id, obj_info in twostream_dict.items():\n",
    "    if 'rgb_files' in obj_info.keys():\n",
    "        ttv_split = obj_info['ttv_split']\n",
    "        if ttv_split == 1: dict_dataset_rgb['train'][obj_id] = obj_info\n",
    "        elif ttv_split == 2: dict_dataset_rgb['valid'][obj_id] = obj_info\n",
    "        elif ttv_split == 3: dict_dataset_rgb['test'][obj_id] = obj_info\n",
    "        else: raise ValueError()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "dict_dataset_opt = {'train':dict(), 'valid':dict(), 'test':dict()}\n",
    "for obj_id, obj_info in twostream_dict.items():\n",
    "    if 'optical_files' in obj_info.keys():\n",
    "        ttv_split = obj_info['ttv_split']\n",
    "        if ttv_split == 1: dict_dataset_opt['train'][obj_id] = obj_info\n",
    "        elif ttv_split == 2: dict_dataset_opt['valid'][obj_id] = obj_info\n",
    "        elif ttv_split == 3: dict_dataset_opt['test'][obj_id] = obj_info\n",
    "        else: raise ValueError()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3265f894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 5938, 'valid': 1236, 'test': 1275}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:len(value) for key,value in dict_dataset_opt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e22b85a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 5629, 'valid': 1175, 'test': 1197}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:len(value) for key,value in dict_dataset_rgb.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "116f1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset_rgb = {key:tf.data.Dataset.from_generator(lambda: generator_dataset_activity_ts_rgb(value), \n",
    "                                       output_types= config.DATASET_TYPE,\n",
    "                                       output_shapes = config.DATASET_SHAPE) \n",
    "              for key,value in dict_dataset_rgb.items()}\n",
    "ts_dataset_opt = {key:tf.data.Dataset.from_generator(lambda: generator_dataset_activity_ts_opt(value), \n",
    "                                       output_types= config.DATASET_TYPE,\n",
    "                                       output_shapes = config.DATASET_SHAPE) \n",
    "              for key,value in dict_dataset_opt.items()}\n",
    "ts_dataset_rgb = {key:dataset.configure_for_performance(value) for key,value in ts_dataset_rgb.items()}\n",
    "ts_dataset_opt = {key:dataset.configure_for_performance(value) for key,value in ts_dataset_opt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b9e727b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <BatchDataset element_spec=(TensorSpec(shape=(None, None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " 'valid': <BatchDataset element_spec=(TensorSpec(shape=(None, None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " 'test': <BatchDataset element_spec=(TensorSpec(shape=(None, None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_dataset_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26ce75",
   "metadata": {},
   "source": [
    "### Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03b89204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Average, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940eb920",
   "metadata": {},
   "source": [
    "#### RGB CNN  - Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3603bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RGB_Model(data, weights = 'imagenet'):\n",
    "    \n",
    "    base_model = InceptionV3(weights=weights, include_top=False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "    predictions = Dense(len(config.ACT_LIST), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f940366",
   "metadata": {},
   "source": [
    "#### Optical Flow CNN - Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d81aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_temporal():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(96, (7, 7), strides=2, padding='same', input_shape=config.IMG_SIZE))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (5, 5), strides=2, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.9))\n",
    "\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.9))\n",
    "\n",
    "    model.add(Dense(self.nb_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d9ba6",
   "metadata": {},
   "source": [
    "### Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c460c5f",
   "metadata": {},
   "source": [
    "#### RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5e2163d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shutil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m rgb_model \u001b[38;5;241m=\u001b[39m RGB_Model(ts_dataset_rgb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m rgb_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      4\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m     10\u001b[0m rgb_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     11\u001b[0m     ts_dataset_rgb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     12\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     13\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mBATCH_SIZE,\n\u001b[1;32m     14\u001b[0m     steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6000\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m config\u001b[38;5;241m.\u001b[39mBATCH_SIZE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     15\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mts_dataset_rgb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     16\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m                  keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, restore_best_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     18\u001b[0m                  keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mts_rgb_ft.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \n\u001b[0;32m---> 19\u001b[0m                  keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run_logdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mts_rgb_ft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m              ]\n\u001b[1;32m     21\u001b[0m )\n",
      "File \u001b[0;32m~/Test/projects/Capstone-Birds-Action-Recognition/TS_Test/utils.py:18\u001b[0m, in \u001b[0;36mget_run_logdir\u001b[0;34m(root_logdir, log_name, overwrite)\u001b[0m\n\u001b[1;32m     16\u001b[0m log_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_logdir, run_id)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(log_path) \u001b[38;5;129;01mand\u001b[39;00m overwrite:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241m.\u001b[39mrmtree(log_path)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_path\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
     ]
    }
   ],
   "source": [
    "rgb_model = RGB_Model(ts_dataset_rgb['train'])\n",
    "\n",
    "rgb_model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "rgb_model.fit(\n",
    "    ts_dataset_rgb['train'],\n",
    "    epochs=10,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    steps_per_epoch = 6000 // config.BATCH_SIZE + 1,\n",
    "    validation_data=ts_dataset_rgb['valid'],\n",
    "    callbacks = [\n",
    "                 keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True, monitor = 'val_accuracy'),\n",
    "                 keras.callbacks.ModelCheckpoint(\"ts_rgb_ft.h5\", save_best_only=True), \n",
    "                 keras.callbacks.TensorBoard(utils.get_run_logdir(log_name = 'ts_rgb_ft'))\n",
    "             ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b990c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

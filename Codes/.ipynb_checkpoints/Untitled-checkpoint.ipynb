{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "insured-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for git\n",
    "# MIL model\n",
    "# used on Argonne server\n",
    "# MIL+attentioin+LN use the new training dataset\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import pathlib\n",
    "from os import makedirs\n",
    "from os.path import exists, join\n",
    "import glob\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "img_height = 200\n",
    "img_width = 200\n",
    "channel_num = 3\n",
    "N = 40\n",
    "batch_size = 16\n",
    "BATCH_SIZE = batch_size\n",
    "IMG_SIZE = (img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "directed-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#input_1, tracks\n",
    "track_input = keras.Input(shape=(N, img_height, img_width, channel_num), name=\"input_1\")  # (?, 40, 200, 200, 3)\n",
    "#input_2, the 1/0 list, identify the real frames with 0, padding frames with 0\n",
    "list_input = keras.Input(shape=(N, 1, 1, 1), name=\"input_2\")  # (?, 40, 1, 1, 1)\n",
    "\n",
    "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(track_input)# (?, 40, 200, 200, 3)\n",
    "\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(16, 3, padding='same'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.LayerNormalization())(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D())(x)\n",
    "\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(32, 3, padding='same'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.LayerNormalization())(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D())(x)\n",
    "\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(32, 3, padding='same'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.LayerNormalization())(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D())(x) # (?, 40, ?, ?, 32)\n",
    "\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(32, 3, padding='same'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.LayerNormalization())(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D())(x) # (?, 40, ?, ?, 32)\n",
    "\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(32, 3, padding='same'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.LayerNormalization())(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D())(x) # (?, 40, ?, ?, 32)\n",
    "\n",
    "# attention layer\n",
    "attention_score = tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAveragePooling2D())(x) # (?, 40, 32)\n",
    "attention_score = tf.keras.layers.Reshape((40, 1, 1, 32))(attention_score) # ?, 40, 1, 1, 32\n",
    "attention_score = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(4, 1, padding='same', activation='relu'))(attention_score) # ?, 40, 1, 1, 4\n",
    "attention_score = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(32, 1, padding='same'))(attention_score) # ?, 40, 1, 1, 32\n",
    "attention_score = tf.keras.activations.sigmoid(attention_score) # ?, 40, 1, 1, 32\n",
    "\n",
    "x = x * attention_score  # (?, 40, ?, ?, 32)\n",
    "\n",
    "x = x * list_input # (batch_size, 40, ?, ?, 32)\n",
    "x = tf.reduce_sum(x, 1) # (batch_size, ?, ?, 32)\n",
    "x = x / tf.reduce_sum(list_input, 1) # (batch_size, ?, ?, 32)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "Dense_LN_1 = tf.keras.layers.LayerNormalization()\n",
    "x = Dense_LN_1(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(16)(x)\n",
    "Dense_LN_2 = tf.keras.layers.LayerNormalization()\n",
    "x = Dense_LN_2(x)\n",
    "x = tf.keras.activations.relu(x)\n",
    "class_pred = tf.keras.layers.Dense(1, name=\"bnb\")(x)\n",
    "model = keras.Model(\n",
    "    inputs=[track_input, list_input],\n",
    "    outputs=[class_pred],\n",
    ")\n",
    "\n",
    "# from-scratch accuracy metric\n",
    "def tf_count(t, val):\n",
    "    elements_equal_to_value = keras.backend.equal(t, val)\n",
    "    as_ints = keras.backend.cast(elements_equal_to_value, tf.int32)\n",
    "    count = keras.backend.sum(as_ints,0)\n",
    "    return count\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_pred = tf.nn.sigmoid(y_pred)\n",
    "    y_pred = tf.where(y_pred < 0.5, 0.0, 1.0)\n",
    "    correct_count = tf_count(y_true, y_pred)\n",
    "    total_count = keras.backend.shape(y_true)[0]\n",
    "    return correct_count/total_count\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"bnb\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    },\n",
    "    loss_weights=[1.0],\n",
    "    metrics={\"bnb\": [accuracy]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "neutral-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/project2/msca/projects/AvianSolar/ImageDataset/raw_dataset\"\n",
    "\n",
    "\n",
    "all_images = pd.read_csv(data_dir + \"/all_image_merged.csv\")\n",
    "all_images = all_images[all_images['image_count'] >= 5]\n",
    "all_images = all_images.sort_values(by=['obj_id', 'frame'])\n",
    "\n",
    "\n",
    "all_images['full_file'] = data_dir + os.path.sep + all_images['day_dir'] + os.path.sep + all_images['camera_dir'] + os.path.sep + all_images['video_dir'] + os.path.sep + all_images['track_dir'].astype(str) + os.path.sep + all_images['image_file']\n",
    "\n",
    "image_count = len(all_images)\n",
    "# png for the avian dataset\n",
    "real_image_count = len(pd.unique(all_images.obj_id))\n",
    "train_ratio = 0.80\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "train_rows = all_images[all_images['ttv_split'] == 1]\n",
    "test_rows = all_images[all_images['ttv_split'] == 2]\n",
    "val_rows = all_images[all_images['ttv_split'] == 3]\n",
    "\n",
    "\n",
    "flag_val_ds = 0\n",
    "flag_train_ds = 0\n",
    "flag_test_ds = 0\n",
    "\n",
    "# num_total_test_tracks = tf.data.experimental.cardinality(test_ds).numpy()\n",
    "\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The third to last is the class-directory in our avian solar dataset case\n",
    "    label = tf.strings.to_number(parts[-1], out_type=tf.int64, name=None)\n",
    "    # tf.strings.to_number(parts[-1], out_type=tf.int64, name=None)\n",
    "    # Integer encode the label\n",
    "    return label\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "    return tf.image.resize(img, [img_height, img_width])\n",
    "\n",
    "# train data generator\n",
    "def generator_train():\n",
    "    for id in pd.unique(train_rows.obj_id):\n",
    "        current_track_rows = train_rows[train_rows.obj_id == id]\n",
    "        label = pd.unique(current_track_rows.obj_cat_binary)\n",
    "        track_img_list = current_track_rows['full_file'].values.tolist()\n",
    "        # total number of frames in the track\n",
    "        img_num = len(track_img_list)\n",
    "        # record the real frame as 1, zero-padding fake frame as 0\n",
    "        mark_tensor = np.zeros([N,])\n",
    "        # the counted N frames in track as input_1\n",
    "        img_list = []\n",
    "        if img_num < N:\n",
    "            for i in range(img_num):\n",
    "                mark_tensor[i] = 1\n",
    "                img = tf.io.read_file(track_img_list[i])\n",
    "                # print(track_img_list[i])\n",
    "                img = decode_img(img)\n",
    "                img_list.append(img)\n",
    "            imgs = tf.stack(img_list)\n",
    "            zero_pads = tf.zeros([N - img_num, img_height, img_width, channel_num], tf.float32)\n",
    "            imgs = tf.concat([imgs, zero_pads], 0)\n",
    "        else:\n",
    "            # use the middle N frames\n",
    "            begin_num = math.floor((img_num - N) / 2)\n",
    "            for i in range(N):\n",
    "                mark_tensor[i] = 1\n",
    "                img = tf.io.read_file(track_img_list[begin_num + i])\n",
    "                # print(track_img_list[begin_num + i])\n",
    "                img = decode_img(img)\n",
    "                img_list.append(img)\n",
    "            imgs = tf.stack(img_list)\n",
    "        mark_tensor = tf.convert_to_tensor(mark_tensor, dtype=tf.float32)\n",
    "        mark_tensor = tf.reshape(mark_tensor, [N, 1, 1, 1])\n",
    "        yield {\"input_1\": imgs, \"input_2\": mark_tensor}, label\n",
    "\n",
    "\n",
    "# val data generator\n",
    "def generator_val():\n",
    "    for id in pd.unique(val_rows.obj_id):\n",
    "        current_track_rows = val_rows[val_rows.obj_id == id]\n",
    "        label = pd.unique(current_track_rows.obj_cat_binary)\n",
    "        track_img_list = current_track_rows['full_file'].values.tolist()\n",
    "        # total number of frames in the track\n",
    "        img_num = len(track_img_list)\n",
    "        # record the real frame as 1, zero fake as 0\n",
    "        mark_tensor = np.zeros([N,])\n",
    "        # the counted N frames in track as input_1\n",
    "        img_list = []\n",
    "        if img_num < N:\n",
    "            for i in range(img_num):\n",
    "                mark_tensor[i] = 1\n",
    "                img = tf.io.read_file(track_img_list[i])\n",
    "                # print(track_img_list[i])\n",
    "                img = decode_img(img)\n",
    "                img_list.append(img)\n",
    "            imgs = tf.stack(img_list)\n",
    "            zero_pads = tf.zeros([N - img_num, img_height, img_width, channel_num], tf.float32)\n",
    "            imgs = tf.concat([imgs, zero_pads], 0)\n",
    "        else:\n",
    "            # use the middle N frames\n",
    "            begin_num = math.floor((img_num - N) / 2)\n",
    "            for i in range(N):\n",
    "                mark_tensor[i] = 1\n",
    "                img = tf.io.read_file(track_img_list[begin_num + i])\n",
    "                # print(track_img_list[begin_num + i])\n",
    "                img = decode_img(img)\n",
    "                img_list.append(img)\n",
    "            imgs = tf.stack(img_list)\n",
    "        mark_tensor = tf.convert_to_tensor(mark_tensor, dtype=tf.float32)\n",
    "        mark_tensor = tf.reshape(mark_tensor, [N, 1, 1, 1])\n",
    "        yield {\"input_1\": imgs, \"input_2\": mark_tensor}, label\n",
    "\n",
    "# test data generator\n",
    "def generator_test():\n",
    "    for id in pd.unique(test_rows.obj_id):\n",
    "        current_track_rows = test_rows[test_rows.obj_id == id]\n",
    "        label = pd.unique(current_track_rows.obj_cat_binary)\n",
    "        track_img_list = current_track_rows['full_file'].values.tolist()\n",
    "        # total number of frames in the track\n",
    "        img_num = len(track_img_list)\n",
    "        # record the real frame as 1, zero fake as 0\n",
    "        mark_tensor = np.zeros([N,])\n",
    "        # the counted N frames in track as input_1\n",
    "        img_list = []\n",
    "        if img_num < N:\n",
    "            for i in range(img_num):\n",
    "                mark_tensor[i] = 1\n",
    "                img = tf.io.read_file(track_img_list[i])\n",
    "                # print(track_img_list[i])\n",
    "                img = decode_img(img)\n",
    "                img_list.append(img)\n",
    "            imgs = tf.stack(img_list)\n",
    "            zero_pads = tf.zeros([N - img_num, img_height, img_width, channel_num], tf.float32)\n",
    "            imgs = tf.concat([imgs, zero_pads], 0)\n",
    "        else:\n",
    "            # use the middle N frames\n",
    "            begin_num = math.floor((img_num - N) / 2)\n",
    "            for i in range(N):\n",
    "                mark_tensor[i] = 1\n",
    "                img = tf.io.read_file(track_img_list[begin_num + i])\n",
    "                # print(track_img_list[begin_num + i])\n",
    "                img = decode_img(img)\n",
    "                img_list.append(img)\n",
    "            imgs = tf.stack(img_list)\n",
    "        mark_tensor = tf.convert_to_tensor(mark_tensor, dtype=tf.float32)\n",
    "        mark_tensor = tf.reshape(mark_tensor, [N, 1, 1, 1])\n",
    "        yield {\"input_1\": imgs, \"input_2\": mark_tensor}, label\n",
    "\n",
    "train_ds_temp = tf.data.Dataset.from_generator(generator_train, output_types=({\"input_1\": tf.float32, \"input_2\": tf.float32}, tf.int64))\n",
    "val_ds_temp = tf.data.Dataset.from_generator(generator_val, output_types=({\"input_1\": tf.float32, \"input_2\": tf.float32}, tf.int64))\n",
    "test_ds_temp = tf.data.Dataset.from_generator(generator_test, output_types=({\"input_1\": tf.float32, \"input_2\": tf.float32}, tf.int64))\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "train_ds_temp = configure_for_performance(train_ds_temp)\n",
    "val_ds_temp = configure_for_performance(val_ds_temp)\n",
    "test_ds_temp = configure_for_performance(test_ds_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fewer-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_ds_temp:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detailed-imagination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x[0]['input_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "known-research",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1), dtype=int64, numpy=\n",
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "super-viewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function accuracy at 0x7f0ecc23e040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function accuracy at 0x7f0ecc23e040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  10/2155 [..............................] - ETA: 2:49:43 - loss: 0.6056 - accuracy: 0.6510"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ff81d5c8a004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the MIL model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_ds_temp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project2/msca/ivy2/software2/install/Anaconda3-2020.07/envs/MSCA_31009/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project2/msca/ivy2/software2/install/Anaconda3-2020.07/envs/MSCA_31009/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project2/msca/ivy2/software2/install/Anaconda3-2020.07/envs/MSCA_31009/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project2/msca/ivy2/software2/install/Anaconda3-2020.07/envs/MSCA_31009/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project2/msca/ivy2/software2/install/Anaconda3-2020.07/envs/MSCA_31009/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/project2/msca/ivy2/software2/install/Anaconda3-2020.07/envs/MSCA_31009/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project2/msca/ivy2/software2/install/Anaconda3-2020.07/envs/MSCA_31009/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the MIL model\n",
    "model.fit(\n",
    "    train_ds_temp,\n",
    "    epochs=15,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    steps_per_epoch = 2155,\n",
    "    validation_data=val_ds_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "objective-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda. get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-merchant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
